<p align="center">
  <img alt="Dynamic_Vertex_Renderer" src="https://github.com/Alexander-Kahanek/NintendAI/assets/8111664/237aab06-1a20-4da3-879f-f1df025d36a0"
</p>
<h1 align="center"> 
  NintendAI
</h1>

<p align="center">
  <a href="https://github.com/SgtR0ck/City_Simulator">
    <img src="https://img.shields.io/badge/version-1.0.0-green.svg?style=plastic">
  </a>
  <img src="https://img.shields.io/badge/language-Python-FFD43B.svg?style=plastic&logo=Python">
  <img src="https://img.shields.io/badge/framework-Jupyter-F37626.svg?style=plastic&logo=Jupyter">
  </a>
</p>

## Introduction

This is an implementation of Reinforcement Learning on Super Mario Bros. A Double Deep Q-Network (DDQN) was used from [This wonderful blog post here](https://blog.paperspace.com/building-double-deep-q-network-super-mario-bros/); however, we have made some edits to the code. Mainly, comments and quality of life updates.

Our Mario learning - https://www.youtube.com/watch?v=WrNR8HqOe4U

Our Mario well trained/"smart" - https://www.youtube.com/watch?v=NGEl7csTNqg
 
## Requirements

Python (3.8.8)


## Code Files

Below are a summary of all the files in this repository:

+ `blog/`
  - super_mario.ipynb
    + the original DDQN codebase
+ GoMarioGo.ipynb
  - the python notebook to render previous training models
+ NintendAI.py
  - the python script that holds our edited version of the DDQN codebase 

 
## Contributers

+ **Alexander Kahanek**
* **Chet Lockwood** - [Atoms-x](https://github.com/Atoms-x)
+ **Marcus Summers**
